---
layout: post
title:  How to use Class Activation Maps (CAM) for Explainable AI in Semantic Segmentation!
date:   2023-10-20
description: Introduction to CAM, explanation of different types of CAMs in semantic segmentation, showcasing some example code using CAM, and CAM results in my project!
tags: deep-learning machine-learning image-segmentation project-update
categories: posts
---

In this post, I will briefly describe Class Activation Maps (CAM) and some of its popular subtypes, usages in semantic segmentation,
and then finally post some code and results in utilizing CAM in my own semantic segmentation project using [H&E images](/projects/1_project/).

---

## **Table of Contents:**
- ### [What are Class Activation Maps (CAM)?](#what-are-cam)
- ### [CAMs in Image Semantic Segmentation:](#cams-in-image-seg)
- ### [Utilizing CAM in My Project](#cam-in-my-proj)

---

<a id="what-are-cam"></a>
## **What are Class Activation Maps (CAM) ?**
*Class activation maps*, henceforth referred to as *CAM*, can be thought of as heatmaps that can highlight the regions of a query image that are most important for the
network's classification or segmentation decision. Before introducing CAMs, *why do we want to look at CAMs in the first place?*

CAMs are probably one of the most popular and easy-to-do explainable AI metrics, which aim to understand and interpret the decisions made by built machine learning models. 
Let's come up with an example where CAMs would be useful: Let's say I work for a AI company and we built a machine learning model that looks at a chest x-ray and is able to detect a rare disease that occurs 1% of the time with 99% sensitivity (so the model itself is
sensitive (or has high recall), so it isn't saying no all the time and has 99% accuracy). However, by utilizing CAMs before deploying the model, I find out that the model is actually only looking at a circle at the corner of the x-ray image to detect
the rare disease. Upon checking the images used for training/validation/testing, they all had a circle at the corner that the hospital used to specify that this was a positive image. **Without CAMs, we would have no idea this was the case
and would've been deploying a completely useless model!**

Like the above made-up example, traditionally, CAMs were developed to be used for image classification, as utilization of CAM was limited to specific types of architectures,
which are CNNs with global average pooling (GAP) and a final fully connected layer. Most image classification models use GAP and a final fully connected layer followed by the output
activation function (assume multi-class, so we use softmax) for turning logits into final prediction probability/results. The last layer before the GAP and fully connected layer is the layer that holds the "feature map",
which captures subtle, fine semantic details of the training images. Therefore, the linear combination of the feature map
This is beautifully summarized in the diagram below:

<img src = "/assets/images/CAMs/CAM_summarized.jpg" width = "835" height = "392" class = "center">
<figcaption> Diagram showing CAM for an image classification task. </figcaption>
<br>

As seen in the above diagram, the class activation map is generated by a linear combination of all the $$n$$ weights for the specific class (in the above case, the Australian terrier)
and all the $$n$$ feature maps

<a id="cams-in-image-seg"></a>
## CAMs in Image Semantic Segmentation: **


<a id="cam-in-my-proj"></a>
## **Utilizing CAM in My Project:**


Code:


```python
CAMmethod = "GradCAMElementWise"
with GradCAMElementWise(model = model, target_layers = target_layers, use_cuda = torch.cuda.is_available()) as cam:
    grayscale_cam = cam(input_tensor=input_tensor,targets=targets)[0,:]
    cam_image = show_cam_on_image(rgb_img, grayscale_cam, use_rgb=True)

```





*Image credits to:*
- [Image Classification CAM Diagram](http://cnnlocalization.csail.mit.edu/)

